{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import statsmodels.api as sm\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from collections import deque\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "{'divide': 'ignore', 'over': 'warn', 'under': 'ignore', 'invalid': 'ignore'}"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set some options\n",
    "np.set_printoptions(precision=3)\n",
    "np.seterr(divide='ignore',invalid='ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "# define data and util functions\n",
    "\n",
    "def marital_status_to_num(val):\n",
    "    if val == 'M':\n",
    "        return 0\n",
    "    elif val == 'S':\n",
    "        return 1\n",
    "    elif val == 'D':\n",
    "        return 2\n",
    "    elif val == 'W':\n",
    "        return 3\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def marital_status_to_str(val):\n",
    "    if val == 0:\n",
    "        return 'married'\n",
    "    elif val == 1:\n",
    "        return 'single'\n",
    "    elif val == 2:\n",
    "        return 'divorced'\n",
    "    elif val == 3:\n",
    "        return 'widowed'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "data_dict = {\n",
    "    'data': {\n",
    "        'rename': {\n",
    "            'ID Number': 'id',\n",
    "            'Lifetime HC': 'cum_donation',\n",
    "            'Email Present': 'has_email',\n",
    "            'BusPhone Present': 'has_business_phone',\n",
    "            'Grad Year': 'grad_year',\n",
    "            'Marital Status': 'marital_status',\n",
    "            'SpouseID Present': 'has_spousal_record',\n",
    "            'JobTitle Present': 'has_job_title',\n",
    "            'VarsityAth Present': 'has_activity_athlete',\n",
    "            'StudGovt Present': 'has_activity_government',\n",
    "            'OtherStudActs Present': 'has_activity_other',\n",
    "            'Greek Present': 'has_activity_greek',\n",
    "            'Prefix is Mr.': 'is_mr',\n",
    "            'Prefix is Ms.': 'is_ms',\n",
    "            'Prefix is Dr.': 'is_dr',\n",
    "            'Prefix is Mrs.': 'is_mrs'\n",
    "        },\n",
    "        'dtype': {\n",
    "            'ID Number': str,\n",
    "            'Lifetime HC': float,\n",
    "            'Grad Year': int,\n",
    "            'Marital Status': str\n",
    "        }\n",
    "    },\n",
    "    'dummy': {\n",
    "        'list': [\n",
    "            'cum_range',\n",
    "            'grad_decade',\n",
    "            'imp_marital_status',\n",
    "        ],\n",
    "        'prefix': {\n",
    "            'cum_range': 'bin_cum_range',\n",
    "            'grad_decade': 'bin_grad_decade',\n",
    "            'imp_marital_status': 'bin_imp_marital_status'\n",
    "        },\n",
    "        'giving': {\n",
    "            'bins': [\n",
    "                0.00,\n",
    "                1.00,\n",
    "                1000.00,\n",
    "                10000.00,\n",
    "                25000.00,\n",
    "                50000.00,\n",
    "                100000.00,\n",
    "                250000.00,\n",
    "                500000.00,\n",
    "                1000000.00,\n",
    "                2500000.00,\n",
    "                5000000.00,\n",
    "                10000000.00,\n",
    "                15000000.00\n",
    "            ],\n",
    "            'labels': [\n",
    "                '$0',\n",
    "                '$1-$999.99',\n",
    "                '$1K-$9.99K',\n",
    "                '$10K-$24.99K',\n",
    "                '$25K-$49.99K',\n",
    "                '$50K-$99.99K',\n",
    "                '$100K-$249.99K',\n",
    "                '$250K-$499.99K',\n",
    "                '$500K-$999.99K',\n",
    "                '$1M-$2.49M',\n",
    "                '$2.5M-$4.99M',\n",
    "                '$5M-$9.99M',\n",
    "                '$10M-$14.99M'\n",
    "            ]\n",
    "        },\n",
    "        'grad': {\n",
    "            'bins': [\n",
    "                1900,\n",
    "                1910,\n",
    "                1920,\n",
    "                1930,\n",
    "                1940,\n",
    "                1950,\n",
    "                1960,\n",
    "                1970,\n",
    "                1980,\n",
    "                1990,\n",
    "                2000,\n",
    "                2010,\n",
    "                2020\n",
    "            ],\n",
    "            'labels': [\n",
    "                '1900s',\n",
    "                '1910s',\n",
    "                '1920s',\n",
    "                '1930s',\n",
    "                '1940s',\n",
    "                '1950s',\n",
    "                '1960s',\n",
    "                '1970s',\n",
    "                '1980s',\n",
    "                '1990s',\n",
    "                '2000s',\n",
    "                '2010s'\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    'cols': {\n",
    "        'bools': [\n",
    "            'has_email',\n",
    "            'has_business_phone',\n",
    "            'has_spousal_record',\n",
    "            'has_job_title',\n",
    "            'has_activity_athlete',\n",
    "            'has_activity_government',\n",
    "            'has_activity_other',\n",
    "            'has_activity_greek',\n",
    "            'is_mr',\n",
    "            'is_ms',\n",
    "            'is_dr',\n",
    "            'is_mrs',\n",
    "            'has_donated'\n",
    "        ],\n",
    "        'bin_grad': [\n",
    "            'bin_grad_decade_1900s',\n",
    "            'bin_grad_decade_1910s',\n",
    "            'bin_grad_decade_1920s',\n",
    "            'bin_grad_decade_1930s',\n",
    "            'bin_grad_decade_1940s',\n",
    "            'bin_grad_decade_1950s',\n",
    "            'bin_grad_decade_1960s',\n",
    "            'bin_grad_decade_1970s',\n",
    "            'bin_grad_decade_1980s',\n",
    "            'bin_grad_decade_1990s',\n",
    "            'bin_grad_decade_2000s',\n",
    "            'bin_grad_decade_2010s'\n",
    "        ],\n",
    "        'bin_giving': [\n",
    "            'bin_cum_range_$0',\n",
    "            'bin_cum_range_$1-$999.99',\n",
    "            'bin_cum_range_$1K-$9.99K',\n",
    "            'bin_cum_range_$10K-$24.99K',\n",
    "            'bin_cum_range_$25K-$49.99K',\n",
    "            'bin_cum_range_$50K-$99.99K',\n",
    "            'bin_cum_range_$100K-$249.99K',\n",
    "            'bin_cum_range_$250K-$499.99K',\n",
    "            'bin_cum_range_$500K-$999.99K',\n",
    "            'bin_cum_range_$1M-$2.49M',\n",
    "            'bin_cum_range_$2.5M-$4.99M',\n",
    "            'bin_cum_range_$5M-$9.99M',\n",
    "            'bin_cum_range_$10M-$14.99M'\n",
    "        ],\n",
    "        'bin_marital': [\n",
    "            'bin_imp_marital_status_divorced',\n",
    "            'bin_imp_marital_status_married',\n",
    "            'bin_imp_marital_status_single',\n",
    "            'bin_imp_marital_status_widowed'\n",
    "        ],\n",
    "        'log': [\n",
    "            'has_donated'\n",
    "        ],\n",
    "        'lin': [\n",
    "            'cum_donation'\n",
    "        ]\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/.local/share/virtualenvs/assignment2-vA0J_QZc/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "project_dir = os.path.join(os.path.abspath(''),os.pardir)\n",
    "data_dir = os.path.join(project_dir,'data')\n",
    "data_raw_dir = os.path.join(data_dir,'raw')\n",
    "\n",
    "file_list = []\n",
    "\n",
    "for file in os.scandir(data_raw_dir):\n",
    "    file_list.append(os.path.join(data_raw_dir,file.name))\n",
    "\n",
    "df = pd.read_excel(io=file_list[0],\n",
    "                   sheet_name='Sheet1',\n",
    "                   dtype=data_dict['data']['dtype'])\n",
    "df = df.rename(columns=data_dict['data']['rename'])\n",
    "dre_df = df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "# drop irrelevant columns\n",
    "df = df.drop(columns='id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "# create a logistic column version of cum_donation_value called has_donated as an additional target variable\n",
    "df['has_donated'] = np.where(df['cum_donation']>0.0,1,0)\n",
    "\n",
    "y_log = df[['has_donated']]\n",
    "y_lin = df[['cum_donation']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "# imputing\n",
    "df['marital_status'] = df['marital_status'].apply(marital_status_to_num)\n",
    "df.loc[df['marital_status'].isnull(),'m_marital_status'] = 1\n",
    "df.loc[df['marital_status'].notnull(),'m_marital_status'] = 0\n",
    "\n",
    "df_marital_status = df[['m_marital_status']]\n",
    "df = df.drop(columns='m_marital_status')\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df = pd.DataFrame(imputer.fit_transform(df),columns=df.columns)\n",
    "df = df.rename(columns={'marital_status': 'imp_marital_status'})\n",
    "df = pd.concat((df,df_marital_status),axis=1)\n",
    "\n",
    "df['imp_marital_status'] = df['imp_marital_status'].round().astype(int)\n",
    "df['imp_marital_status'] = df['imp_marital_status'].apply(marital_status_to_str)\n",
    "df[data_dict['cols']['bools']] = df[data_dict['cols']['bools']].astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "# binning\n",
    "df.sort_values('cum_donation',inplace=True)\n",
    "df['cum_range'] = \\\n",
    "    pd.cut(x=df['cum_donation'],\n",
    "           bins=data_dict['dummy']['giving']['bins'],\n",
    "           labels=data_dict['dummy']['giving']['labels'],\n",
    "           right=False)\n",
    "df.sort_values('grad_year',inplace=True)\n",
    "df['grad_decade'] = pd.cut(x=df['grad_year'],\n",
    "                           bins=data_dict['dummy']['grad']['bins'],\n",
    "                           labels=data_dict['dummy']['grad']['labels'],\n",
    "                           right=False)\n",
    "df.sort_index(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "# dummying\n",
    "dummy_filter = df[data_dict['dummy']['list']]\n",
    "dummy_df = pd.get_dummies(data=dummy_filter,\n",
    "                          prefix=data_dict['dummy']['prefix'],\n",
    "                          columns=data_dict['dummy']['list'])\n",
    "df = pd.concat(([df,dummy_df]),axis=1)\n",
    "\n",
    "# all possible lin/log features\n",
    "X = df.drop(columns=['imp_marital_status','cum_range','grad_decade'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "# Different models will be denoted through an encoded sting of\n",
    "# bits from right to left. As more variety is introduced this\n",
    "# bitwise representation will grow in length.\n",
    "\n",
    "# 0th bit [-1]:         0 - logistic regression\n",
    "#                       1 - linear regression\n",
    "# 1st bit [-2]:         0 - grad_year int\n",
    "#                       1 - grad_year binned\n",
    "# 2nd bit [-3]:         0 - cum_donation float\n",
    "#                       1 - cum_donation binned\n",
    "# 3rd-5th bit [-6:-3]:  000 - no automatic feature selection\n",
    "#                       001 - chi square filtering (chi)\n",
    "#                       010 - Random Forest Importance (rfi)\n",
    "#                       011 - Recursive Feature Elimination Cross Validation (rfe)\n",
    "#                       100 - Forward Feature Elimination (ffe)\n",
    "# 6th-7th bit [-8:-6]:  00 - unscaled\n",
    "#                       01 - MinMaxScaler\n",
    "#                       10 - StandardScaler\n",
    "#                       11 - RobustScaler\n",
    "# 8th bit [-9]:         0 - Cross Fold Validation\n",
    "#                       1 - Stacking\n",
    "\n",
    "# 0th bit: is linear regression\n",
    "\n",
    "dict_3bit = dict()\n",
    "\n",
    "for i in [1,0]:\n",
    "    model_bit = deque()\n",
    "    if i == 1:\n",
    "        model_bit.appendleft('1')\n",
    "        y = y_lin\n",
    "        X = sm.add_constant(X)\n",
    "        feature_list_lv0 = list((Counter(X.columns.tolist())\n",
    "                                 -Counter(data_dict['cols']['lin']))\n",
    "                                .elements())\n",
    "\n",
    "    else:\n",
    "        model_bit.appendleft('0')\n",
    "        y = y_log\n",
    "        X = X\n",
    "        feature_list_lv0 = list((Counter(X.columns.tolist())\n",
    "                                 -Counter(data_dict['cols']['log']))\n",
    "                                .elements())\n",
    "\n",
    "\n",
    "    # 1st bit: is grad_year binned\n",
    "    for j in [1,0]:\n",
    "        if j == 1:\n",
    "            model_bit.appendleft('1')\n",
    "            feature_list_lv1 = list((Counter(feature_list_lv0)\n",
    "                                     -Counter(['grad_year']))\n",
    "                                    .elements())\n",
    "        else:\n",
    "            model_bit.appendleft('0')\n",
    "            feature_list_lv1 = list((Counter(feature_list_lv0)\n",
    "                                     -Counter(data_dict['cols']['bin_grad']))\n",
    "                                    .elements())\n",
    "\n",
    "        # 2nd bit: is cum_donation binned\n",
    "        for k in [1,0]:\n",
    "            feature_list_lv2 = feature_list_lv1\n",
    "            if k == 1:\n",
    "                model_bit.appendleft('1')\n",
    "                feature_list_lv2 = list((Counter(feature_list_lv1)\n",
    "                                         -Counter(['cum_donation']))\n",
    "                                        .elements())\n",
    "            else:\n",
    "                model_bit.appendleft('0')\n",
    "                feature_list_lv2 = list((Counter(feature_list_lv1)\n",
    "                     -Counter(data_dict['cols']['bin_giving']))\n",
    "                    .elements())\n",
    "            bit_str = ''.join(model_bit)\n",
    "\n",
    "            # filter linear regressions where linear target would be\n",
    "            # present\n",
    "            if not re.match('1\\d1',bit_str):\n",
    "                model_dict = {\n",
    "                    bit_str: {\n",
    "                        'y': y,\n",
    "                        'X': X[feature_list_lv2]\n",
    "                    }\n",
    "                }\n",
    "                dict_3bit.update(model_dict)\n",
    "            model_bit.popleft()\n",
    "        model_bit.popleft()\n",
    "    model_bit.popleft()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "# 3th-5th bit: Automatic Feature Selection (afs)\n",
    "# 000 - no automatic feature selection\n",
    "# 001 - chi square filtering (chi)\n",
    "# 010 - Random Forest Importance (rfi)\n",
    "# 011 - Recursive Feature Elimination Cross Validation (rfe)\n",
    "# 100 - Forward Feature Elimination (ffe)\n",
    "\n",
    "def get_chi(bit_str:str, d):\n",
    "    test = SelectKBest(score_func=chi2,k='all')\n",
    "\n",
    "    label = d['y']\n",
    "    features = d['X']\n",
    "\n",
    "    feature_list = list(features.columns)\n",
    "    chi_scores = test.fit(features,label)\n",
    "    chi_list = list(zip(feature_list,chi_scores.scores_))\n",
    "    chi_df = pd.DataFrame(chi_list,columns=['feature','chi'])\n",
    "    chi_df = chi_df[chi_df['chi']>3.8]\n",
    "\n",
    "    filtered_features = chi_df['feature'].tolist()\n",
    "    d.update({'X':d['X'][filtered_features]})\n",
    "    d.update({'afs':chi_df})\n",
    "\n",
    "    return d\n",
    "\n",
    "def get_rfi(bit_str:str, d):\n",
    "    label = d['y']\n",
    "    features = d['X']\n",
    "\n",
    "    feature_list = list(features.columns)\n",
    "    np_features = np.array(features)\n",
    "\n",
    "    if bit_str[-1] == '0':\n",
    "        rf = RandomForestClassifier(n_estimators=1000)\n",
    "    else:\n",
    "        rf = RandomForestRegressor(n_estimators=1000)\n",
    "\n",
    "    rf.fit(np_features,label.values.ravel())\n",
    "    importances = list(rf.feature_importances_)\n",
    "    feature_importances = list(zip(feature_list,importances))\n",
    "    rfi_df = pd.DataFrame(feature_importances,columns=['feature','rfi'])\n",
    "    rfi_df = rfi_df.sort_values(by='rfi',ascending=False)\n",
    "\n",
    "    # filter out features that do not exceed the average importance value\n",
    "    importance_filter = (rfi_df['rfi'].sum())/(rfi_df['rfi'].count())\n",
    "    rfi_df = rfi_df[rfi_df['rfi']>importance_filter]\n",
    "\n",
    "    filtered_features = rfi_df['feature'].tolist()\n",
    "    d.update({'X':d['X'][filtered_features]})\n",
    "    d.update({'afs': rfi_df})\n",
    "\n",
    "    return d\n",
    "\n",
    "def get_rfecv(bit_str, d):\n",
    "    label = d['y']\n",
    "    features = d['X']\n",
    "\n",
    "    feature_list = list(features.columns)\n",
    "\n",
    "    if bit_str[-1] == '0':\n",
    "        estimator = LogisticRegression(max_iter=500)\n",
    "    else:\n",
    "        estimator = LinearRegression()\n",
    "    selector = RFECV(estimator=estimator)\n",
    "    selector.fit(features,label.values.ravel())\n",
    "    ranking = list(selector.support_)\n",
    "    feature_ranking = list(zip(feature_list,ranking))\n",
    "    rfecv_df = pd.DataFrame(feature_ranking,columns=['feature','rfe'])\n",
    "\n",
    "    # filter out features rfe considers insignificant\n",
    "    rfecv_df = rfecv_df[rfecv_df['rfe']==True]\n",
    "\n",
    "    filtered_features = rfecv_df['feature'].tolist()\n",
    "    d.update({'X':d['X'][filtered_features]})\n",
    "    d.update({'afs': rfecv_df})\n",
    "    return d\n",
    "\n",
    "def get_ffe(bit_str:str, d):\n",
    "    label = d['y']\n",
    "    features = d['X']\n",
    "    feature_list = list(features.columns)\n",
    "    ffe = f_regression(features,label.values.ravel())\n",
    "    ffe_list = []\n",
    "    for i in range(0,len(feature_list)):\n",
    "        ffe_list.append({'feature':feature_list[i],\n",
    "                                'ffe':ffe[0][i]})\n",
    "    ffe_df = pd.DataFrame(ffe_list)\n",
    "\n",
    "    ffe_filter = (ffe_df['ffe'].sum()/ffe_df['ffe'].count())\n",
    "    ffe_df = ffe_df[ffe_df['ffe']>ffe_filter]\n",
    "\n",
    "    filtered_features = ffe_df['feature'].tolist()\n",
    "    d.update({'X':d['X'][filtered_features]})\n",
    "    d.update({'afs':ffe_df})\n",
    "    return d\n",
    "\n",
    "dict_6bit = dict()\n",
    "\n",
    "for k_model, v_data in dict_3bit.items():\n",
    "    for auto in [('000', None), ('001', get_chi), ('010', get_rfi),\n",
    "                 ('011', get_rfecv), ('100', get_ffe)]:\n",
    "        model_bit = deque(k_model)\n",
    "        data = v_data.copy()\n",
    "\n",
    "        # skips no automatic feature selection\n",
    "        if auto[0] == '000':\n",
    "            model_bit.appendleft(auto[0])\n",
    "        # skips chi-squaring linear regressions\n",
    "        elif (auto[1] is get_chi) and (bit_str[-1] == '1'):\n",
    "            model_bit.appendleft('000')\n",
    "        else:\n",
    "            model_bit.appendleft(auto[0])\n",
    "            data = auto[1](model_bit,data)\n",
    "        bit_str = ''.join(model_bit)\n",
    "        dict_6bit.update({bit_str: data})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [118]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m ki \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m      7\u001B[0m             ff_dict\u001B[38;5;241m.\u001B[39mupdate({k:vi\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mtolist()})\n\u001B[0;32m----> 9\u001B[0m ff_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mff_dict\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/assignment2-vA0J_QZc/lib/python3.10/site-packages/pandas/core/frame.py:1677\u001B[0m, in \u001B[0;36mDataFrame.from_dict\u001B[0;34m(cls, data, orient, dtype, columns)\u001B[0m\n\u001B[1;32m   1674\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124monly recognize index or columns for orient\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1676\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m orient \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtight\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 1677\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1678\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1679\u001B[0m     realdata \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/assignment2-vA0J_QZc/lib/python3.10/site-packages/pandas/core/frame.py:636\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[0;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[1;32m    630\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_mgr(\n\u001B[1;32m    631\u001B[0m         data, axes\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m\"\u001B[39m: index, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: columns}, dtype\u001B[38;5;241m=\u001B[39mdtype, copy\u001B[38;5;241m=\u001B[39mcopy\n\u001B[1;32m    632\u001B[0m     )\n\u001B[1;32m    634\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m    635\u001B[0m     \u001B[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001B[39;00m\n\u001B[0;32m--> 636\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[43mdict_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmanager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    637\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ma\u001B[38;5;241m.\u001B[39mMaskedArray):\n\u001B[1;32m    638\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mma\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmrecords\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmrecords\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/assignment2-vA0J_QZc/lib/python3.10/site-packages/pandas/core/internals/construction.py:502\u001B[0m, in \u001B[0;36mdict_to_mgr\u001B[0;34m(data, index, columns, dtype, typ, copy)\u001B[0m\n\u001B[1;32m    494\u001B[0m     arrays \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    495\u001B[0m         x\n\u001B[1;32m    496\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x\u001B[38;5;241m.\u001B[39mdtype, ExtensionDtype)\n\u001B[1;32m    497\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m x\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m    498\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m arrays\n\u001B[1;32m    499\u001B[0m     ]\n\u001B[1;32m    500\u001B[0m     \u001B[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001B[39;00m\n\u001B[0;32m--> 502\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marrays_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtyp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconsolidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/assignment2-vA0J_QZc/lib/python3.10/site-packages/pandas/core/internals/construction.py:120\u001B[0m, in \u001B[0;36marrays_to_mgr\u001B[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001B[0m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verify_integrity:\n\u001B[1;32m    118\u001B[0m     \u001B[38;5;66;03m# figure out the index, if necessary\u001B[39;00m\n\u001B[1;32m    119\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 120\u001B[0m         index \u001B[38;5;241m=\u001B[39m \u001B[43m_extract_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    122\u001B[0m         index \u001B[38;5;241m=\u001B[39m ensure_index(index)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/assignment2-vA0J_QZc/lib/python3.10/site-packages/pandas/core/internals/construction.py:674\u001B[0m, in \u001B[0;36m_extract_index\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m    672\u001B[0m lengths \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mset\u001B[39m(raw_lengths))\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(lengths) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 674\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll arrays must be of the same length\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    676\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m have_dicts:\n\u001B[1;32m    677\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    678\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    679\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "ff_dict = dict()\n",
    "\n",
    "for k,v in dict_6bit.items():\n",
    "\n",
    "    for ki,vi in v.items():\n",
    "        if ki == 'X':\n",
    "            ff_dict.update({k:vi.columns.tolist()})\n",
    "\n",
    "ff_df = pd.DataFrame.from_dict(ff_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "outputs": [],
   "source": [
    "# 6th-7th bit: Scaling\n",
    "# 00 - unscaled\n",
    "# 01 - MinMaxScaler\n",
    "# 10 - StandardScaler\n",
    "# 11 - RobustScaler\n",
    "\n",
    "dict_8bit = defaultdict()\n",
    "\n",
    "for k_model, v_data in dict_6bit.items():\n",
    "    for scale in [('00',None),('01',MinMaxScaler()),('10',StandardScaler()),\n",
    "                  ('11',RobustScaler())]:\n",
    "        X_scaler = scale[1]\n",
    "        y_scaler = scale[1]\n",
    "        model_bit = deque(k_model)\n",
    "        data = v_data.copy()\n",
    "\n",
    "        y_scale = data['y']\n",
    "        y_scale_labels = list(y_scale.columns)\n",
    "        X_scale = data['X']\n",
    "        X_scale_labels = list(X_scale.columns)\n",
    "\n",
    "        data.update({'y_scale': y_scale,\n",
    "                     'y_scale_labels': y_scale_labels,\n",
    "                     'X_scale': X_scale,\n",
    "                     'X_scale_labels': X_scale_labels,\n",
    "                     'X_scaler': None,\n",
    "                     'y_scaler': None})\n",
    "\n",
    "        if scale[0] == '00':\n",
    "            model_bit.appendleft(scale[0])\n",
    "\n",
    "        else:\n",
    "            if model_bit[-1] == '1':\n",
    "                y_scale = y_scaler.fit_transform(np.array(y_scale)\n",
    "                                                  .reshape(-1,1))\n",
    "                data.update({'y_scale': y_scale,\n",
    "                             'y_scaler': y_scaler})\n",
    "\n",
    "            model_bit.appendleft(scale[0])\n",
    "            X_scale = X_scaler.fit_transform(X_scale)\n",
    "            data.update({'X_scale': X_scale,\n",
    "                         'X_scaler': X_scaler})\n",
    "        bit_str = ''.join(model_bit)\n",
    "        dict_8bit.update({bit_str: data})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "00000011\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 31)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 31)\n",
      "\t X_scale_labels \t (31,)\n",
      "01000011\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 31)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 31)\n",
      "\t X_scale_labels \t (31,)\n",
      "10000011\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 31)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 31)\n",
      "\t X_scale_labels \t (31,)\n",
      "11000011\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 31)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 31)\n",
      "\t X_scale_labels \t (31,)\n",
      "00010011\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 9)\n",
      "\t afs \t (9, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 9)\n",
      "\t X_scale_labels \t (9,)\n",
      "01010011\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 9)\n",
      "\t afs \t (9, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 9)\n",
      "\t X_scale_labels \t (9,)\n",
      "10010011\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 9)\n",
      "\t afs \t (9, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 9)\n",
      "\t X_scale_labels \t (9,)\n",
      "11010011\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 9)\n",
      "\t afs \t (9, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 9)\n",
      "\t X_scale_labels \t (9,)\n",
      "00011011\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 8)\n",
      "\t afs \t (8, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 8)\n",
      "\t X_scale_labels \t (8,)\n",
      "01011011\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 8)\n",
      "\t afs \t (8, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 8)\n",
      "\t X_scale_labels \t (8,)\n",
      "10011011\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 8)\n",
      "\t afs \t (8, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 8)\n",
      "\t X_scale_labels \t (8,)\n",
      "11011011\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 8)\n",
      "\t afs \t (8, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 8)\n",
      "\t X_scale_labels \t (8,)\n",
      "00100011\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 4)\n",
      "\t afs \t (4, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 4)\n",
      "\t X_scale_labels \t (4,)\n",
      "01100011\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 4)\n",
      "\t afs \t (4, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 4)\n",
      "\t X_scale_labels \t (4,)\n",
      "10100011\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 4)\n",
      "\t afs \t (4, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 4)\n",
      "\t X_scale_labels \t (4,)\n",
      "11100011\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 4)\n",
      "\t afs \t (4, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 4)\n",
      "\t X_scale_labels \t (4,)\n",
      "00000001\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 20)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 20)\n",
      "\t X_scale_labels \t (20,)\n",
      "01000001\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 20)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 20)\n",
      "\t X_scale_labels \t (20,)\n",
      "10000001\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 20)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 20)\n",
      "\t X_scale_labels \t (20,)\n",
      "11000001\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 20)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 20)\n",
      "\t X_scale_labels \t (20,)\n",
      "00010001\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 7)\n",
      "\t afs \t (7, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 7)\n",
      "\t X_scale_labels \t (7,)\n",
      "01010001\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 7)\n",
      "\t afs \t (7, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 7)\n",
      "\t X_scale_labels \t (7,)\n",
      "10010001\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 7)\n",
      "\t afs \t (7, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 7)\n",
      "\t X_scale_labels \t (7,)\n",
      "11010001\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 7)\n",
      "\t afs \t (7, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 7)\n",
      "\t X_scale_labels \t (7,)\n",
      "00011001\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 3)\n",
      "\t afs \t (3, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 3)\n",
      "\t X_scale_labels \t (3,)\n",
      "01011001\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 3)\n",
      "\t afs \t (3, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 3)\n",
      "\t X_scale_labels \t (3,)\n",
      "10011001\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 3)\n",
      "\t afs \t (3, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 3)\n",
      "\t X_scale_labels \t (3,)\n",
      "11011001\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 3)\n",
      "\t afs \t (3, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 3)\n",
      "\t X_scale_labels \t (3,)\n",
      "00100001\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 4)\n",
      "\t afs \t (4, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 4)\n",
      "\t X_scale_labels \t (4,)\n",
      "01100001\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 4)\n",
      "\t afs \t (4, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 4)\n",
      "\t X_scale_labels \t (4,)\n",
      "10100001\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 4)\n",
      "\t afs \t (4, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 4)\n",
      "\t X_scale_labels \t (4,)\n",
      "11100001\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 4)\n",
      "\t afs \t (4, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 4)\n",
      "\t X_scale_labels \t (4,)\n",
      "00000110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 43)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 43)\n",
      "\t X_scale_labels \t (43,)\n",
      "01000110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 43)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 43)\n",
      "\t X_scale_labels \t (43,)\n",
      "10000110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 43)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 43)\n",
      "\t X_scale_labels \t (43,)\n",
      "11000110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 43)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 43)\n",
      "\t X_scale_labels \t (43,)\n",
      "00001110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 33)\n",
      "\t afs \t (33, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 33)\n",
      "\t X_scale_labels \t (33,)\n",
      "01001110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 33)\n",
      "\t afs \t (33, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 33)\n",
      "\t X_scale_labels \t (33,)\n",
      "10001110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 33)\n",
      "\t afs \t (33, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 33)\n",
      "\t X_scale_labels \t (33,)\n",
      "11001110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 33)\n",
      "\t afs \t (33, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 33)\n",
      "\t X_scale_labels \t (33,)\n",
      "00010110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 4)\n",
      "\t afs \t (4, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 4)\n",
      "\t X_scale_labels \t (4,)\n",
      "01010110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 4)\n",
      "\t afs \t (4, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 4)\n",
      "\t X_scale_labels \t (4,)\n",
      "10010110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 4)\n",
      "\t afs \t (4, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 4)\n",
      "\t X_scale_labels \t (4,)\n",
      "11010110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 4)\n",
      "\t afs \t (4, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 4)\n",
      "\t X_scale_labels \t (4,)\n",
      "00011110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "01011110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "10011110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "11011110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "00100110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "01100110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "10100110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "11100110\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "00000010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 31)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 31)\n",
      "\t X_scale_labels \t (31,)\n",
      "01000010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 31)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 31)\n",
      "\t X_scale_labels \t (31,)\n",
      "10000010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 31)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 31)\n",
      "\t X_scale_labels \t (31,)\n",
      "11000010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 31)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 31)\n",
      "\t X_scale_labels \t (31,)\n",
      "00001010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 26)\n",
      "\t afs \t (26, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 26)\n",
      "\t X_scale_labels \t (26,)\n",
      "01001010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 26)\n",
      "\t afs \t (26, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 26)\n",
      "\t X_scale_labels \t (26,)\n",
      "10001010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 26)\n",
      "\t afs \t (26, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 26)\n",
      "\t X_scale_labels \t (26,)\n",
      "11001010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 26)\n",
      "\t afs \t (26, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 26)\n",
      "\t X_scale_labels \t (26,)\n",
      "00010010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 2)\n",
      "\t afs \t (2, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 2)\n",
      "\t X_scale_labels \t (2,)\n",
      "01010010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 2)\n",
      "\t afs \t (2, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 2)\n",
      "\t X_scale_labels \t (2,)\n",
      "10010010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 2)\n",
      "\t afs \t (2, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 2)\n",
      "\t X_scale_labels \t (2,)\n",
      "11010010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 2)\n",
      "\t afs \t (2, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 2)\n",
      "\t X_scale_labels \t (2,)\n",
      "00011010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "01011010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "10011010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "11011010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "00100010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 9)\n",
      "\t afs \t (9, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 9)\n",
      "\t X_scale_labels \t (9,)\n",
      "01100010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 9)\n",
      "\t afs \t (9, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 9)\n",
      "\t X_scale_labels \t (9,)\n",
      "10100010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 9)\n",
      "\t afs \t (9, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 9)\n",
      "\t X_scale_labels \t (9,)\n",
      "11100010\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 9)\n",
      "\t afs \t (9, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 9)\n",
      "\t X_scale_labels \t (9,)\n",
      "00000100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 32)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 32)\n",
      "\t X_scale_labels \t (32,)\n",
      "01000100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 32)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 32)\n",
      "\t X_scale_labels \t (32,)\n",
      "10000100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 32)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 32)\n",
      "\t X_scale_labels \t (32,)\n",
      "11000100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 32)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 32)\n",
      "\t X_scale_labels \t (32,)\n",
      "00001100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 26)\n",
      "\t afs \t (26, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 26)\n",
      "\t X_scale_labels \t (26,)\n",
      "01001100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 26)\n",
      "\t afs \t (26, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 26)\n",
      "\t X_scale_labels \t (26,)\n",
      "10001100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 26)\n",
      "\t afs \t (26, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 26)\n",
      "\t X_scale_labels \t (26,)\n",
      "11001100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 26)\n",
      "\t afs \t (26, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 26)\n",
      "\t X_scale_labels \t (26,)\n",
      "00010100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 3)\n",
      "\t afs \t (3, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 3)\n",
      "\t X_scale_labels \t (3,)\n",
      "01010100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 3)\n",
      "\t afs \t (3, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 3)\n",
      "\t X_scale_labels \t (3,)\n",
      "10010100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 3)\n",
      "\t afs \t (3, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 3)\n",
      "\t X_scale_labels \t (3,)\n",
      "11010100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 3)\n",
      "\t afs \t (3, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 3)\n",
      "\t X_scale_labels \t (3,)\n",
      "00011100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "01011100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "10011100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "11011100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "00100100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "01100100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "10100100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "11100100\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "00000000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 20)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 20)\n",
      "\t X_scale_labels \t (20,)\n",
      "01000000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 20)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 20)\n",
      "\t X_scale_labels \t (20,)\n",
      "10000000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 20)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 20)\n",
      "\t X_scale_labels \t (20,)\n",
      "11000000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 20)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 20)\n",
      "\t X_scale_labels \t (20,)\n",
      "00001000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 19)\n",
      "\t afs \t (19, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 19)\n",
      "\t X_scale_labels \t (19,)\n",
      "01001000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 19)\n",
      "\t afs \t (19, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 19)\n",
      "\t X_scale_labels \t (19,)\n",
      "10001000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 19)\n",
      "\t afs \t (19, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 19)\n",
      "\t X_scale_labels \t (19,)\n",
      "11001000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 19)\n",
      "\t afs \t (19, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 19)\n",
      "\t X_scale_labels \t (19,)\n",
      "00010000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 2)\n",
      "\t afs \t (2, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 2)\n",
      "\t X_scale_labels \t (2,)\n",
      "01010000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 2)\n",
      "\t afs \t (2, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 2)\n",
      "\t X_scale_labels \t (2,)\n",
      "10010000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 2)\n",
      "\t afs \t (2, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 2)\n",
      "\t X_scale_labels \t (2,)\n",
      "11010000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 2)\n",
      "\t afs \t (2, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 2)\n",
      "\t X_scale_labels \t (2,)\n",
      "00011000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "01011000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "10011000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "11011000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 1)\n",
      "\t afs \t (1, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 1)\n",
      "\t X_scale_labels \t (1,)\n",
      "00100000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 7)\n",
      "\t afs \t (7, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 7)\n",
      "\t X_scale_labels \t (7,)\n",
      "01100000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 7)\n",
      "\t afs \t (7, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 7)\n",
      "\t X_scale_labels \t (7,)\n",
      "10100000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 7)\n",
      "\t afs \t (7, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 7)\n",
      "\t X_scale_labels \t (7,)\n",
      "11100000\n",
      "\t y \t (5000, 1)\n",
      "\t X \t (5000, 7)\n",
      "\t afs \t (7, 2)\n",
      "\t y_scale \t (5000, 1)\n",
      "\t y_scale_labels \t (1,)\n",
      "\t X_scale \t (5000, 7)\n",
      "\t X_scale_labels \t (7,)\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_8bit))\n",
    "\n",
    "for k,v in dict_8bit.items():\n",
    "    print(k)\n",
    "    for ki,vi in v.items():\n",
    "        print('\\t',ki,'\\t',np.shape(vi))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "outputs": [],
   "source": [
    "# 9th bit: Modeling\n",
    "# also rescaling\n",
    "# 1 - Stacking\n",
    "# 0 - Cross-fold validation\n",
    "\n",
    "def get_unfit_regressors():\n",
    "    models = list()\n",
    "    models.append(ElasticNet())\n",
    "    models.append(SVR(gamma='scale'))\n",
    "    models.append(DecisionTreeRegressor())\n",
    "    models.append(AdaBoostRegressor())\n",
    "    models.append(RandomForestRegressor(n_estimators=10))\n",
    "    models.append(ExtraTreesRegressor(n_estimators=10))\n",
    "    return models\n",
    "\n",
    "def get_unfit_classifiers():\n",
    "    models = list()\n",
    "    models.append(LogisticRegression())\n",
    "    models.append(DecisionTreeClassifier())\n",
    "    models.append(AdaBoostClassifier())\n",
    "    models.append(RandomForestClassifier(n_estimators=10))\n",
    "    return models\n",
    "\n",
    "def evaluate_model_regressor(y_test, predictions, model):\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = round(np.sqrt(mse),3)\n",
    "    print(\" RMSE:\" + str(rmse) + \" \" + model.__class__.__name__)\n",
    "\n",
    "def evaluate_model_classifier(y_test, predictions, model):\n",
    "    precision = round(metrics.precision_score(y_test, predictions),2)\n",
    "    recall = round(metrics.recall_score(y_test, predictions), 2)\n",
    "    f1 = round(metrics.f1_score(y_test, predictions), 2)\n",
    "    accuracy = round(metrics.accuracy_score(y_test, predictions), 2)\n",
    "\n",
    "def fit_base_models(X_train, y_train, X_test, models,y_scaler):\n",
    "    dfPredictions = pd.DataFrame()\n",
    "    # Fit base model and store its predictions in dataframe.\n",
    "    for i in range(0, len(models)):\n",
    "        models[i].fit(X_train, y_train)\n",
    "        predictions = models[i].predict(X_test)\n",
    "        if y_scaler:\n",
    "            predictions = y_scaler.inverse_transform(np.array(predictions).reshape(-1,1))\n",
    "        colName = str(i)\n",
    "        # Add base model predictions to column of data frame.\n",
    "        dfPredictions[colName] = predictions\n",
    "    return dfPredictions, models\n",
    "\n",
    "def fit_stacked_model_regressor(X, y):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def fit_stacked_model_classifier(X, y):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def get_cross_fold_log(X,y,X_scaler,y_scaler,selection_name,selection,X_label,\n",
    "                       y_label,k_fold):\n",
    "    accuracy_list = list()\n",
    "    precision_list = list()\n",
    "    recall_list = list()\n",
    "    f1_list = list()\n",
    "    coef_list = list()\n",
    "\n",
    "    for train_index, test_index in k_fold.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        lm = LogisticRegression(fit_intercept=True,\n",
    "                                solver='liblinear')\n",
    "        lm.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "        y_pred = lm.predict(X_test)\n",
    "        if y_scaler:\n",
    "            y_pred = y_scaler.inverse_transform(np.array(y_pred).reshape(-1,1))\n",
    "\n",
    "        accuracy = metrics.accuracy_score(y_test,y_pred)\n",
    "        precision = metrics.precision_score(y_test,y_pred,zero_division=0)\n",
    "        recall = metrics.recall_score(y_test,y_pred,zero_division=0)\n",
    "        f1 = metrics.f1_score(y_test,y_pred,zero_division=0)\n",
    "\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "        coef_list.append(pd.DataFrame({\"feature\":X_label,\"coef\":lm.coef_[0]}))\n",
    "\n",
    "    return {\n",
    "        'accuracy_avg' : np.mean(accuracy_list),\n",
    "        'accuracy_sd' : np.std(accuracy_list),\n",
    "        'precision_avg' : np.mean(precision_list),\n",
    "        'precision_sd' : np.std(precision_list),\n",
    "        'recall_avg' : np.mean(recall_list),\n",
    "        'recall_sd' : np.std(recall_list),\n",
    "        'f1_avg' : np.mean(f1_list),\n",
    "        'f1_sd' : np.std(f1_list),\n",
    "        'coef' : pd.concat(coef_list).groupby('feature',as_index=False,sort=False)['coef'].mean()\n",
    "    }\n",
    "\n",
    "def get_cross_fold_lin(X,y,X_scaler,y_scaler,selection_name,selection,X_label,\n",
    "                       y_label,k_fold):\n",
    "    rmseList = list()\n",
    "    bicList = list()\n",
    "    rsquareLst = list()\n",
    "    coef_list = list()\n",
    "\n",
    "    for train_index, test_index in k_fold.split(X):\n",
    "        X_train = X.loc[X.index.isin(train_index)]\n",
    "        X_test  = X.loc[X.index.isin(test_index)]\n",
    "        y_train = y.loc[y.index.isin(train_index)]\n",
    "        y_test  = y.loc[y.index.isin(test_index)]\n",
    "\n",
    "        # Perform linear regression.\n",
    "        model = sm.OLS(y_train, X_train).fit()\n",
    "        y_pred = model.predict(X_test)\n",
    "        if y_scaler:\n",
    "            y_pred = y_scaler.inverse_transform(np.array(y_pred).reshape(-1,1))\n",
    "\n",
    "        mse    = metrics.mean_squared_error(y_test, y_pred)\n",
    "        rmse   = np.sqrt(mse)\n",
    "        bic    = model.bic\n",
    "        rsqr   = model.rsquared\n",
    "\n",
    "        rmseList.append(rmse)\n",
    "        bicList.append(bic)\n",
    "        rsquareLst.append(rsqr)\n",
    "        coef_list.append(pd.DataFrame({'feature':X_label,'coef':model.params}))\n",
    "\n",
    "    return {\n",
    "        'rmse_avg': np.mean(rmseList),\n",
    "        'rmse_sd': np.std(rmseList),\n",
    "        'bic_avg': np.mean(bicList),\n",
    "        'bic_sd': np.std(bicList),\n",
    "        'rsquare_avg': np.mean(rsquareLst),\n",
    "        'rsquare_sd': np.std(rsquareLst),\n",
    "        'coef': pd.concat(coef_list).groupby('feature',as_index=False,sort=False)['coef'].mean()\n",
    "    }\n",
    "\n",
    "dict_9bit = defaultdict()\n",
    "\n",
    "for k_model, v_data in dict_8bit.items():\n",
    "    for model in ['0','1']:\n",
    "        model_bit = deque(k_model)\n",
    "        data = v_data.copy()\n",
    "\n",
    "        # unwrap the dict\n",
    "        X = data['X_scale']\n",
    "        y = data['y_scale']\n",
    "        X_scaler = data['X_scaler']\n",
    "        y_scaler = data['y_scaler']\n",
    "\n",
    "        for i in [('000', None), ('001', 'chi'), ('010', 'rfi'),\n",
    "                 ('011', 'rfecv'), ('100', 'ffe')]:\n",
    "            if bit_str[-6:-3] == i[0]:\n",
    "                selection_name = i[1]\n",
    "                selection = data['afs']\n",
    "        X_label = data['X_scale_labels']\n",
    "        y_label = data['y_scale_labels']\n",
    "\n",
    "        if model == '0':\n",
    "            model_bit.appendleft('0')\n",
    "            k_fold = KFold(n_splits=3,shuffle=True)\n",
    "            if model_bit[-1] == '0':\n",
    "                result = get_cross_fold_log(X,y,X_scaler,y_scaler,selection_name,selection,X_label,y_label,k_fold)\n",
    "            else:\n",
    "                result = get_cross_fold_lin(X,y,X_scaler,y_scaler,selection_name,selection,X_label,y_label,k_fold)\n",
    "        else:\n",
    "            model_bit.appendleft('1')\n",
    "            X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.70)\n",
    "            X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.50)\n",
    "\n",
    "            if model_bit[-1] == '0':\n",
    "                unfit_models = get_unfit_classifiers()\n",
    "            else:\n",
    "                unfit_models = get_unfit_regressors()\n",
    "\n",
    "            pred_df, models = fit_base_models(X_train,y_train,X_test,unfit_models,y_scaler)\n",
    "\n",
    "            if model_bit[-1] == '0':\n",
    "                stacked_model = fit_stacked_model_classifier(pred_df,y_test)\n",
    "            else:\n",
    "                stacked_model = fit_stacked_model_regressor(pred_df,y_test)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "The dataset used in this assignment is provided by Kevin MacDonell and is available at <a href=\"https://cooldata.wordpress.com/cooldatabook/\">CoolData blog</a>. It accompanies a freely published book **COOL DATA: A how-to guide for predictive modeling for higher education advancement and nonprofits using multiple linear regression in Data Desk** (Current version: 1.1.0, 2018-01-13)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Exploration\n",
    "On import - and after some minor tweaking of column names - the data appears as follows:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count  Dtype   \n",
      "---  ------                   --------------  -----   \n",
      " 0   id                       5000 non-null   object  \n",
      " 1   cum_donation             5000 non-null   float64 \n",
      " 2   has_email                5000 non-null   int64   \n",
      " 3   has_business_phone       5000 non-null   int64   \n",
      " 4   grad_year                5000 non-null   int64   \n",
      " 5   marital_status           4965 non-null   object  \n",
      " 6   has_spousal_record       5000 non-null   int64   \n",
      " 7   has_job_title            5000 non-null   int64   \n",
      " 8   has_activity_athlete     5000 non-null   int64   \n",
      " 9   has_activity_government  5000 non-null   int64   \n",
      " 10  has_activity_other       5000 non-null   int64   \n",
      " 11  has_activity_greek       5000 non-null   int64   \n",
      " 12  is_mr                    5000 non-null   int64   \n",
      " 13  is_ms                    5000 non-null   int64   \n",
      " 14  is_dr                    5000 non-null   int64   \n",
      " 15  is_mrs                   5000 non-null   int64   \n",
      " 16  grad_decade              5000 non-null   category\n",
      " 17  cum_range                5000 non-null   category\n",
      "dtypes: category(2), float64(1), int64(13), object(2)\n",
      "memory usage: 635.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dre_df.info(show_counts=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notable here is the largest amount of columns that indicate boolean descriptions of the alumni in question. From this, I am confident in concluding that this dataset has already been significantly cleaned and transformed from its original state to one that is more amenable to statistical analysis.\n",
    "\n",
    "Additional features of interest include the <code>marital_status</code> column, which is the only instance of nulls in this dataset that will require imputing. Furthermore, the <code>cum_donation</code> column contains <code>float64</code> data indicating the total amount the constituent has donated to the client's organization. Lastly, the <code>grad_year</code> column contains information about when the alumni graduated. <code>id</code> will be dropped as it does not have any statistical significance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Boolean Features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_email                  5000\n",
      "has_business_phone         5000\n",
      "has_spousal_record         5000\n",
      "has_job_title              5000\n",
      "has_activity_athlete       5000\n",
      "has_activity_government    5000\n",
      "has_activity_other         5000\n",
      "has_activity_greek         5000\n",
      "is_mr                      5000\n",
      "is_ms                      5000\n",
      "is_dr                      5000\n",
      "is_mrs                     5000\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "                            0     1\nhas_email                2125  2875\nhas_business_phone       3171  1829\nhas_spousal_record       4184   816\nhas_job_title            2626  2374\nhas_activity_athlete     4703   297\nhas_activity_government  4902    98\nhas_activity_other       4145   855\nhas_activity_greek       4380   620\nis_mr                    2968  2032\nis_ms                    3752  1248\nis_dr                    3908  1092\nis_mrs                   4484   516",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>has_email</th>\n      <td>2125</td>\n      <td>2875</td>\n    </tr>\n    <tr>\n      <th>has_business_phone</th>\n      <td>3171</td>\n      <td>1829</td>\n    </tr>\n    <tr>\n      <th>has_spousal_record</th>\n      <td>4184</td>\n      <td>816</td>\n    </tr>\n    <tr>\n      <th>has_job_title</th>\n      <td>2626</td>\n      <td>2374</td>\n    </tr>\n    <tr>\n      <th>has_activity_athlete</th>\n      <td>4703</td>\n      <td>297</td>\n    </tr>\n    <tr>\n      <th>has_activity_government</th>\n      <td>4902</td>\n      <td>98</td>\n    </tr>\n    <tr>\n      <th>has_activity_other</th>\n      <td>4145</td>\n      <td>855</td>\n    </tr>\n    <tr>\n      <th>has_activity_greek</th>\n      <td>4380</td>\n      <td>620</td>\n    </tr>\n    <tr>\n      <th>is_mr</th>\n      <td>2968</td>\n      <td>2032</td>\n    </tr>\n    <tr>\n      <th>is_ms</th>\n      <td>3752</td>\n      <td>1248</td>\n    </tr>\n    <tr>\n      <th>is_dr</th>\n      <td>3908</td>\n      <td>1092</td>\n    </tr>\n    <tr>\n      <th>is_mrs</th>\n      <td>4484</td>\n      <td>516</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring all the boolean columns\n",
    "dre_bool = dre_df[['has_email',\n",
    "                  'has_business_phone',\n",
    "                  'has_spousal_record',\n",
    "                  'has_job_title',\n",
    "                  'has_activity_athlete',\n",
    "                  'has_activity_government',\n",
    "                  'has_activity_other',\n",
    "                  'has_activity_greek',\n",
    "                  'is_mr',\n",
    "                  'is_ms',\n",
    "                  'is_dr',\n",
    "                  'is_mrs']]\n",
    "dre_bool_report = dre_bool.apply(pd.value_counts)\n",
    "print(dre_bool_report.sum())\n",
    "dre_bool_report.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "All of the boolean columns add up to the length of the dataset, confirming there are no <code>null</code> values present. Additionally, the <code>dre_bool_report</code> confirms that the only two values present across all booleans columns are in fact 1 and 0."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dre_bool_report.T.plot.bar(stacked=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at a stacked bar chart of the all boolean columns, it is interesting to note that the incidence of <code>True</code> indicators is on average low. The only two columns that exceed 50% are has_email and has_job_title. In terms of descriptive information to have on a dataset of alumni, these are high value assets. Having a present email address allows the client organization to engage in direct mail campaigns and inform the constituent of engagement opportunities with the client organization. Having a job title would allow further slicing of the database by focusing on senior positions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Marital Status"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null count 35\n",
      "value count 4965\n"
     ]
    },
    {
     "data": {
      "text/plain": "M    2160\nU    1586\nS     996\nD     110\nW     106\nE       4\nP       2\nZ       1\nName: marital_status, dtype: int64"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the category column marital_status\n",
    "dre_column = 'marital_status'\n",
    "print('null count',dre_df[dre_column].isnull().sum())\n",
    "print('value count',dre_df[dre_column].notnull().sum())\n",
    "dre_marital_report = dre_df[dre_column].value_counts()\n",
    "dre_marital_report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Marital Status has a number of issues that need to be addressed before this feature can be utilized in a statistical model. First among them is the presence of <code>null</code> values. Second, would be determining what the categories indicate. MacDonell has this to say about the provenance of the categories for this column:\n",
    "\n",
    "> M, for Married, quite a few are Unknown (U), and almost a thousand are Single (S). W and D probably stand for Widowed and Divorced. As for the others, your guess is as good as mine.\n",
    "\n",
    "(2018, MacDonell, pg. 18)\n",
    "\n",
    "With this information, a general strategy can be formed for cleaning up and imputing this column. The <code>null</code> values, along with <code>E</code>, <code>P</code>, and <code>Z</code> can be reclassified to <code>U</code>."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dre_marital_report.plot.bar(x='marital_status',y='count',rot=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The majority of constituents are either Married, Unknown, or Single, this indicates that the client organization only comes back into contact with their constituents after they have established themselves. If the client had a direct connection with the registrar of the school they raise funds for, it would be far more likely that the single population would be far higher. This is a good indicator for accuracy in our models as it means it is likely consituents in their database have made an initial connection with them."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grad Year"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null count 0\n",
      "value count 5000\n",
      "min val 1911\n",
      "max val 2013\n"
     ]
    },
    {
     "data": {
      "text/plain": "1911      1\n1930      1\n1931      1\n1932      1\n1934      1\n       ... \n2009    135\n2010    130\n2011    129\n2012    103\n2013     12\nName: grad_year, Length: 83, dtype: int64"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the grad_year column\n",
    "dre_column = 'grad_year'\n",
    "print('null count',dre_df[dre_column].isnull().sum())\n",
    "print('value count',dre_df[dre_column].notnull().sum())\n",
    "print('min val', dre_df[dre_column].min())\n",
    "print('max val', dre_df[dre_column].max())\n",
    "dre_grad_report = dre_df[dre_column].value_counts()\n",
    "dre_grad_report.sort_index(inplace=True)\n",
    "dre_grad_report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "1900s       0\n1910s       1\n1920s       0\n1930s      12\n1940s      78\n1950s     249\n1960s     497\n1970s     761\n1980s     864\n1990s    1096\n2000s    1068\n2010s     374\nName: grad_decade, dtype: int64"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's categorize the date by decade to aid in visualization\n",
    "dre_df['grad_decade'] = pd.cut(x=dre_df['grad_year'],\n",
    "                           bins=data_dict['dummy']['grad']['bins'],\n",
    "                           labels=data_dict['dummy']['grad']['labels'],\n",
    "                           right=False)\n",
    "dre_column = 'grad_decade'\n",
    "dre_grad_decade_report = dre_df[dre_column].value_counts()\n",
    "dre_grad_decade_report.sort_index(inplace=True)\n",
    "dre_grad_decade_report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aggregating this column by decade makes the information far easier to parse. However, I am uncertain if this will provide for a stronger or weaker model, so both versions will be tested (binned and unbinned grad_year). In terms of the distribution, ~40% of the constituents have graduated in the past 3 decades, which is typical for post secondary engagement."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dre_grad_decade_report.plot.bar()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cumulative Donation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null count 0\n",
      "value count 5000\n",
      "min val 0.0\n",
      "max val 11187224.58\n"
     ]
    }
   ],
   "source": [
    "# Explore the cum_donation column\n",
    "dre_column = 'cum_donation'\n",
    "print('null count',dre_df[dre_column].isnull().sum())\n",
    "print('value count',dre_df[dre_column].notnull().sum())\n",
    "print('min val', dre_df[dre_column].min())\n",
    "print('max val', dre_df[dre_column].max())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "$0                2555\n$1-$999.99        1843\n$1K-$9.99K         518\n$10K-$24.99K        46\n$25K-$49.99K        14\n$50K-$99.99K         7\n$100K-$249.99K      10\n$250K-$499.99K       4\n$500K-$999.99K       0\n$1M-$2.49M           2\n$2.5M-$4.99M         0\n$5M-$9.99M           0\n$10M-$14.99M         1\nName: cum_range, dtype: int64"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dre_df['cum_range'] = pd.cut(x=dre_df['cum_donation'],\n",
    "                             bins=data_dict['dummy']['giving']['bins'],\n",
    "                             labels=data_dict['dummy']['giving']['labels'],\n",
    "                             right=False)\n",
    "dre_column = 'cum_range'\n",
    "dre_cum_range_report = dre_df[dre_column].value_counts()\n",
    "dre_cum_range_report.sort_index(inplace=True)\n",
    "dre_cum_range_report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Similar to <code>grad_year</code> this information has been binned to aid in visual analysis in addition to providing another avenue for statistical analysis. Cumulative Donations will be modeled in their binned and unbinned states. The size of the bins increase as the magnitude of gift increases. A gift chart as demonstrated above is typical of what is used in practice in the fundraising field. It is constructed in this way to ensure the granularity seen at the lower end of giving is not deviated by larger, more infrequent gifts.\n",
    "\n",
    "More than half of this dataset are alumni who haven't contributed - yet. From there, the curve of donations decreases steeply. The values hear are unsurprising for higher-ed."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dre_cum_range_report.plot.bar()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data-Preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Identifying Significant Features\n",
    "The identification of significant features has been automatically implemented through the use of Chi-Square values (chi), Random Forest Importances (rfi), Recursive Feature Elimination with Cross Fold Validation (rfecv), and Forward Feature Elimination (ffe). Some of these feature selection algorithms choose features automatically - chi with features greater than 3.8 and rfecv are two such examples. In the instances where features are merely provided a weight with regard to their significance, the values were averaged on only features that exceeded that average were retained."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imputing and Variable Creation\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Modeling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scaling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}